{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Text Classification via Logistic Regresssion \n",
    "\n",
    "This homework notebook has been adapted from the PyTorch tutorial [Text Classification with the TorchText Library](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html).\n",
    "\n",
    "[Torchtext](https://pytorch.org/text/stable/index.html) is a library within the PyTorch framework that consists of data processing utilities and popular datasets for natural language processing.\n",
    "\n",
    "In this homework, we will\n",
    "- build a logistic regression model for text classification using bag of words (BoW).\n",
    "- extend the above model to use continuous bag of words (CBoW).\n",
    "- consider some other extensions, such as using a better version of gradient descent.\n",
    "\n",
    "You have to complete **13 tasks**, specified at appropriate places, worth a total of 35 points.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classes Dataset and DataLoader\n",
    "\n",
    "Dataset and DataLoader are PyTorch classes that provides utilities for iterating through and sampling from a dataset. They provide several features for advanced applications (e.g., skim through [this tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) on writing custom datasets and dataloaders).\n",
    "\n",
    "We'll work with the `` AG_NEWS`` dataset included within torchtext, and will write a custom dataloader to create minibatches of examples for training and testing.  The [``AG_NEWS``](https://rdrr.io/cran/textdata/man/dataset_ag_news.html) consists of about 120,000 examples of text from news sources, each labeled with one of 4 classes (world, sports, business, science and technology). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "source": [
    "import torch\r\n",
    "from torchtext.datasets import AG_NEWS\r\n",
    "train_data = AG_NEWS(split='train')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A dataset behaves like an iterator.  So when called in a for loop or using next it returns a sequence of examples, each of which is a pair of label and text."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "source": [
    "example1 = next(train_data)\r\n",
    "example1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "metadata": {},
     "execution_count": 331
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "source": [
    "next(train_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3,\n",
       " 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.')"
      ]
     },
     "metadata": {},
     "execution_count": 332
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "source": [
    "next(train_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\")"
      ]
     },
     "metadata": {},
     "execution_count": 333
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing: tokenizing, converting to BoW\r\n",
    "\r\n",
    "\r\n",
    "In order to convert a piece of text into, say, a BoW vector, we need to do\r\n",
    "\r\n",
    "- Split up the text into a sequence of words or tokens.  This can be a suprisingly complex task because of various uses of apostrophe, uses of contractions, etc.  (E.g., see this [article](https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html) at Stanford.)  We'll simply use a tokenizer provided by torchtext.\r\n",
    "\r\n",
    "- Determine which tokens will be included in our BoW vector, and which will be ignored.  Using too few will degrade prediction performance, while using too many will slow down the system.  We'll only include words that occur in the training set at least a given minimum number of times.\r\n",
    "\r\n",
    "- Convert each included word into an numerical index corresponding to its position on the BoW vectors. Torchtext provide a ``Vocab`` class to help with this. (Alternately, we can convert each word into a dense vector representation using pretrained representations such as [GloVe](https://nlp.stanford.edu/projects/glove/).) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "source": [
    "from torchtext.data.utils import get_tokenizer # \"we'll simply use a tokenizer provided by torchtext\"\r\n",
    "from collections import Counter  # dict subclass for counting hashable objects\r\n",
    "from torchtext.vocab import Vocab\r\n",
    "\r\n",
    "tokenizer = get_tokenizer('basic_english') # tokenizer provided by torchtext\r\n",
    "train_iter = AG_NEWS(split='train') # dataset provided by torchtext\r\n",
    "counter = Counter()  # dict subclass for counting hashable objects\r\n",
    "for (label, line) in train_iter:\r\n",
    "    counter.update(tokenizer(line))\r\n",
    "# Only inlcude words that occur at least 1000 times in the training data.\r\n",
    "vocab = Vocab(counter, min_freq=1000)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "``vocab`` can be used to convert a list of tokens in a list of indices."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "source": [
    "[vocab[token] for token in ['here', 'is', 'an', 'example']]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[476, 22, 31, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 335
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "See the [documentation](https://pytorch.org/text/stable/vocab.html) for ``Vocab.``  Now write code to answer the following:\r\n",
    "- **Task 1** [1 points]: Print the number of words in ``vocab``.\r\n",
    "- **Task 2** [1]: Print the index of the word \"economy\".\r\n",
    "- **Task 3** [1]: Print the word at index 500.\r\n",
    "- **Task 4** [1]: Write code to determine the index associated with words not in the vocabulary. What is that index value?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "source": [
    "### WRITE YOUR CODE BELOW\r\n",
    "print(\"The length of the vocab, two different ways: \",\r\n",
    "      vocab.__len__(), \",\", len(vocab))\r\n",
    "print(\"The index of the token, economy, two different ways: \",\r\n",
    "      vocab.__getitem__(\"economy\"), \",\", vocab[\"economy\"])\r\n",
    "print(\"The word at index 500: \", vocab.itos[500])\r\n",
    "\r\n",
    "def determine_index(token):\r\n",
    "      '''\r\n",
    "      Sets index of unknown token that is outside of vocabulary to 0, which corresponds to \"<unk>\".\r\n",
    "      '''\r\n",
    "      if not vocab[token]:\r\n",
    "            print(f\"{token} is unknown/outside of the vocabulary\")\r\n",
    "            return vocab[\"<unk>\"]\r\n",
    "      else:\r\n",
    "            return vocab[token]\r\n",
    "\r\n",
    "print(\"The index of the token, party: \", determine_index(\"party\"))\r\n",
    "print(\"The index of the token, partyy: \", determine_index(\"partyy\"))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The length of the vocab, two different ways:  633 , 633\n",
      "The index of the token, economy, two different ways:  348 , 348\n",
      "The word at index 500:  party\n",
      "The index of the token, party:  500\n",
      "partyy is unknown/outside of the vocabulary\n",
      "The index of the token, partyy:  0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A [dataloader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) takes a dataset and creates minibatches of examples, each of a specified batch size.  We specify how it processes each example from the dataset via a custom collate function.\n",
    "\n",
    "**Task 5** [5]: Write a collate function ``collate_into_bow`` that accepts a batch of k examples created from the dataset above and returns two tensors:\n",
    "a tensor of shape (k,) containing the labels of the batch, and a tensor of shape (k, m), in which m is the number of tokens in the vocabulary, containing the bow vectors for the examples. Further:\n",
    "\n",
    "1. The labels in the dataset are numbers 1 to 4. Since PyTorch is 0-indexed, please convert them to numbers 0 to 3 in the collate function.\n",
    "2. Remember that the entry in each bow vector is the **relative frequency** of the word in the corresponding text."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "source": [
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "def collate_into_bow(batch):\r\n",
    "    \r\n",
    "## WRITE YOUR CODE BELOW    \r\n",
    "    labels = []\r\n",
    "    words_lst = []\r\n",
    "    for (label, words) in batch:\r\n",
    "        labels.append(int(label) - 1)\r\n",
    "        word_occurrence = Counter(words.split()) # count occurences for each word in example\r\n",
    "        words_lst.append(word_occurrence) \r\n",
    "    labels = torch.tensor(labels)\r\n",
    "\r\n",
    "    bow_vector = torch.zeros(len(words_lst), len(vocab))  # initiate bow vector of size (k, m)\r\n",
    "    for i in range(len(words_lst)):\r\n",
    "        for key, value in words_lst[i].items():\r\n",
    "            # replace ith example row and vocab index column with word occurence percentage\r\n",
    "            bow_vector[i, vocab[key]] = value/len(words_lst)\r\n",
    "\r\n",
    "    return labels, bow_vector\r\n",
    "\r\n",
    "\r\n",
    "def test_collate():\r\n",
    "    w1 = vocab.itos[3]\r\n",
    "    w2 = vocab.itos[7]\r\n",
    "    w3 = vocab.itos[8]\r\n",
    "    w4 = vocab.itos[9]\r\n",
    "    examples = [\r\n",
    "        (1, \" \".join([w1, w2, w3, w4])),\r\n",
    "        (2, \" \".join([w2, w1, w3, w4])),\r\n",
    "        (4, \" \".join([w4, w2, w3, w4])),\r\n",
    "        (3, \" \".join([w2, w2, w2, w4])),\r\n",
    "    ]\r\n",
    "    bowt = torch.tensor(\r\n",
    "        [\r\n",
    "            [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25],\r\n",
    "            [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25],\r\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.50],\r\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.25],\r\n",
    "        ]) \r\n",
    "    lt, tt = collate_into_bow(examples)\r\n",
    "    assert torch.equal(lt, torch.tensor([0, 1, 3, 2]))\r\n",
    "    assert torch.equal(tt[:,:10], bowt)\r\n",
    "    assert tt[:,10:].sum().item() == 0.00\r\n",
    "    print('Test passed.')\r\n",
    "    \r\n",
    "test_collate()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test passed.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The collate function is provided to a dataloader as shown below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "source": [
    "train_iter = AG_NEWS(split='train')\r\n",
    "dataloader = DataLoader(train_iter, batch_size=16, shuffle=False, \r\n",
    "                        collate_fn=collate_into_bow)\r\n",
    "for idx, (lt, tt) in enumerate(dataloader):\r\n",
    "    print(idx, lt.shape, tt.shape)\r\n",
    "    if idx == 4: break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 torch.Size([16]) torch.Size([16, 633])\n",
      "1 torch.Size([16]) torch.Size([16, 633])\n",
      "2 torch.Size([16]) torch.Size([16, 633])\n",
      "3 torch.Size([16]) torch.Size([16, 633])\n",
      "4 torch.Size([16]) torch.Size([16, 633])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A BoW Classifier Class\n",
    "\n",
    "**Task 6** [3]: Write a BoWClassifier class with one single linear layer,\n",
    "similar to the one in [Robert Guthrie's tutorial](https://pytorch.org/tutorials/beginner/nlp/deep_learning_tutorial.html#sphx-glr-beginner-nlp-deep-learning-tutorial-py).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "source": [
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "class BoWClassifier(nn.Module):\r\n",
    "    \r\n",
    "## WRITE YOUR CODE BELOW\r\n",
    "    def __init__(self, num_labels, vocab_size):\r\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\r\n",
    "        # just always do it in an nn.Module\r\n",
    "        super(BoWClassifier, self).__init__()\r\n",
    "        self.linear = nn.Linear(in_features=vocab_size,\r\n",
    "                                out_features=num_labels)\r\n",
    "\r\n",
    "    def forward(self, bow_vec):\r\n",
    "        # Pass the input through the linear layer - then through log_softmax.\r\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following creates a model object of the class BoWClassifier.\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "source": [
    "train_data = AG_NEWS(split='train')\r\n",
    "num_labels = len(set([label for (label, text) in train_iter]))\r\n",
    "vocab_size = len(vocab)\r\n",
    "model = BoWClassifier(num_labels, vocab_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training an epoch\n",
    "\n",
    "The code below is similar to what we saw in Gutherie's tutorial. It prints the loss every 500 iterations. ``model.train()`` is used by PyTorch to set the model in training model.  This usually only impacts some advanced architectures."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "source": [
    "import time\r\n",
    "\r\n",
    "loss_function = torch.nn.NLLLoss()\r\n",
    "\r\n",
    "def train_an_epoch(dataloader):\r\n",
    "    model.train() # Sets the module in training mode.\r\n",
    "    log_interval = 500\r\n",
    "\r\n",
    "    for idx, (label, text) in enumerate(dataloader):\r\n",
    "        model.zero_grad()\r\n",
    "        log_probs = model(text)\r\n",
    "        loss = loss_function(log_probs, label)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        if idx % log_interval == 0 and idx > 0:\r\n",
    "            print(f'At iteration {idx} the loss is {loss:.3f}.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing average accuracy on a validation set\n",
    "\n",
    "**Task 7** [3]: Write a function ``get_accuracy`` to compute the average accuracy of the model for a given dataloader.  Your code should iterate through all the examples, for each find the predicted label with the highest probability, and count the number of examples in which this predicted label is correct.  It should then return the average accuracy. Remember that although most batches will have a fixed number of examples (the given batch size), the last batch may have fewer examples.  So you should explicitly count the number of examples in each batch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "source": [
    "def get_accuracy(dataloader):\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "    ## WRITE YOUR CODE BELOW.    \r\n",
    "        total_acc, total_count = 0, 0\r\n",
    "        for idx, (label, word_idxs) in enumerate(dataloader):\r\n",
    "            log_probs = model(word_idxs)\r\n",
    "            total_acc += (log_probs.argmax(1) == label).sum().item()\r\n",
    "            total_count += label.size(0)\r\n",
    "    return total_acc/total_count\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create training, validation, and testing dataloaders\n",
    "\n",
    "Since the original ``AG_NEWS`` has no valid dataset, we split the training\n",
    "dataset into train/valid sets with a split ratio of 0.95 (train) and\n",
    "0.05 (valid). Here we use\n",
    "[``torch.utils.data.dataset.random_split``](https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split)\n",
    "function in PyTorch core library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "source": [
    "from torch.utils.data.dataset import random_split\r\n",
    "\r\n",
    "BATCH_SIZE = 64 # batch size for training\r\n",
    "  \r\n",
    "train_valid_data, test_data = AG_NEWS()\r\n",
    "train_valid_data = list(train_valid_data)\r\n",
    "num_train = int(len(train_valid_data) * 0.95)\r\n",
    "num_valid = len(train_valid_data) - num_train\r\n",
    "train_data, valid_data = random_split(\r\n",
    "    train_valid_data, [num_train, num_valid])\r\n",
    "\r\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE,\r\n",
    "                              shuffle=True, \r\n",
    "                              collate_fn=collate_into_bow)\r\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE,\r\n",
    "                              shuffle=False, \r\n",
    "                              collate_fn=collate_into_bow)\r\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE,\r\n",
    "                             shuffle=False, \r\n",
    "                             collate_fn=collate_into_bow)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "EPOCHS = 10 # epoch \r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=3)\r\n",
    "\r\n",
    "validation_accuracies = []\r\n",
    "for epoch in range(1, EPOCHS + 1):\r\n",
    "    epoch_start_time = time.time()\r\n",
    "    train_an_epoch(train_dataloader)\r\n",
    "    validation_accuracy = get_accuracy(valid_dataloader)\r\n",
    "    validation_accuracies.append(validation_accuracy)\r\n",
    "    time_taken = time.time() - epoch_start_time\r\n",
    "    print()\r\n",
    "    print(\r\n",
    "        f'After epoch {epoch} the validation accuracy is {validation_accuracy:.3f}.')\r\n",
    "    print()\r\n",
    "\r\n",
    "plt.title(\"Accuracy by Number of Epochs\")\r\n",
    "plt.ylabel(\"Accuracy\")\r\n",
    "plt.xlabel(\"Epochs\")\r\n",
    "plt.grid()\r\n",
    "plt.plot(range(1, EPOCHS+1), validation_accuracies, \"r\", label=\"validation accuracy\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig(f\"Accuracy{EPOCHS}epochs.jpg\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "At iteration 500 the loss is 1.406.\n",
      "At iteration 1000 the loss is 1.423.\n",
      "At iteration 1500 the loss is 1.353.\n",
      "\n",
      "After epoch 1 the validation accuracy is 0.366.\n",
      "\n",
      "At iteration 500 the loss is 1.300.\n",
      "At iteration 1000 the loss is 1.275.\n",
      "At iteration 1500 the loss is 1.267.\n",
      "\n",
      "After epoch 2 the validation accuracy is 0.382.\n",
      "\n",
      "At iteration 500 the loss is 1.319.\n",
      "At iteration 1000 the loss is 1.216.\n",
      "At iteration 1500 the loss is 1.289.\n",
      "\n",
      "After epoch 3 the validation accuracy is 0.484.\n",
      "\n",
      "At iteration 500 the loss is 1.223.\n",
      "At iteration 1000 the loss is 1.252.\n",
      "At iteration 1500 the loss is 1.286.\n",
      "\n",
      "After epoch 4 the validation accuracy is 0.390.\n",
      "\n",
      "At iteration 500 the loss is 1.157.\n",
      "At iteration 1000 the loss is 1.200.\n",
      "At iteration 1500 the loss is 1.141.\n",
      "\n",
      "After epoch 5 the validation accuracy is 0.265.\n",
      "\n",
      "At iteration 500 the loss is 1.157.\n",
      "At iteration 1000 the loss is 1.234.\n",
      "At iteration 1500 the loss is 1.143.\n",
      "\n",
      "After epoch 6 the validation accuracy is 0.507.\n",
      "\n",
      "At iteration 500 the loss is 1.172.\n",
      "At iteration 1000 the loss is 1.186.\n",
      "At iteration 1500 the loss is 1.194.\n",
      "\n",
      "After epoch 7 the validation accuracy is 0.286.\n",
      "\n",
      "At iteration 500 the loss is 1.111.\n",
      "At iteration 1000 the loss is 1.201.\n",
      "At iteration 1500 the loss is 1.114.\n",
      "\n",
      "After epoch 8 the validation accuracy is 0.498.\n",
      "\n",
      "At iteration 500 the loss is 1.123.\n",
      "At iteration 1000 the loss is 1.182.\n",
      "At iteration 1500 the loss is 1.272.\n",
      "\n",
      "After epoch 9 the validation accuracy is 0.478.\n",
      "\n",
      "At iteration 500 the loss is 1.099.\n",
      "At iteration 1000 the loss is 1.128.\n",
      "At iteration 1500 the loss is 1.179.\n",
      "\n",
      "After epoch 10 the validation accuracy is 0.536.\n",
      "\n",
      "At iteration 500 the loss is 1.084.\n",
      "At iteration 1000 the loss is 1.206.\n",
      "At iteration 1500 the loss is 1.074.\n",
      "\n",
      "After epoch 11 the validation accuracy is 0.510.\n",
      "\n",
      "At iteration 500 the loss is 1.104.\n",
      "At iteration 1000 the loss is 1.179.\n",
      "At iteration 1500 the loss is 1.029.\n",
      "\n",
      "After epoch 12 the validation accuracy is 0.523.\n",
      "\n",
      "At iteration 500 the loss is 1.066.\n",
      "At iteration 1000 the loss is 1.084.\n",
      "At iteration 1500 the loss is 1.177.\n",
      "\n",
      "After epoch 13 the validation accuracy is 0.550.\n",
      "\n",
      "At iteration 500 the loss is 1.009.\n",
      "At iteration 1000 the loss is 1.034.\n",
      "At iteration 1500 the loss is 1.108.\n",
      "\n",
      "After epoch 14 the validation accuracy is 0.515.\n",
      "\n",
      "At iteration 500 the loss is 1.124.\n",
      "At iteration 1000 the loss is 1.069.\n",
      "At iteration 1500 the loss is 1.085.\n",
      "\n",
      "After epoch 15 the validation accuracy is 0.525.\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 8** [5]: Run the model for a sufficient number of epochs such that the model shows overfitting, and submit a pdf of the plot of accuracy against number of epochs.  Determine the optimal number of epochs to train for.  Write code to estimate the accuracy of your model corresponding to this optimal number of epocs and report this estimated accuracy.\n",
    "\n",
    "**Task 9** [2]: Notice above that both the printed losses and the accuracies keep varying and do not necessary increase or decrease in a steady fashion.  List all the reasons you can think of for this variance in the loss and the accuracy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "source": [
    "'''\r\n",
    "Task 8: Determine the optimal number of epochs to train for.\r\n",
    "We can see from the graph that the accuracy increases rapidly until just before 10 epochs, \r\n",
    "at which point the accuracy continues to increases slow and steadily. For the sake of time, \r\n",
    "10 epochs should be enough time to capture the spike in accuracy, while not being too long to \r\n",
    "get just a few percentage points higher.\r\n",
    "\r\n",
    "Task 9: This high variability may be caused by a learning rate that is too high. \r\n",
    "This is a gradient decent algorithm, and the gradient should to converge to zero with ideal parameters.\r\n",
    "Currently the learning rate is set to 3, and perhaps the model is overcorrecting the bottom of the loss curve each time.\r\n",
    "I would try reducing the learning rate to something that more easily converges to zero without taking too much longer to compute.\r\n",
    "'''\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nTask 8: Determine the optimal number of epochs to train for.\\nWe can see from the graph that the accuracy increases rapidly until just before 10 epochs, \\nat which point the accuracy continues to increases slow and steadily. For the sake of time, \\n10 epochs should be enough time to capture the spike in accuracy, while not being too long to \\nget just a few percentage points higher.\\n\\nTask 9: This high variability may be caused by a learning rate that is too high. \\nThis is a gradient decent algorithm, and the gradient should to converge to zero with ideal parameters.\\nCurrently the learning rate is set to 3, and perhaps the model is overcorrecting the bottom of the loss curve each time.\\nI would try reducing the learning rate to something that more easily converges to zero without taking too much longer to compute.\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 345
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding a pre-trained embedding\n",
    "\n",
    "[GloVe](https://nlp.stanford.edu/projects/glove/) is set of dense vector representations, or embeddings.  Torchtext has support for GloVe. (It takes several minutes the first time---to download.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "source": [
    "from itertools import combinations\r\n",
    "from torchtext.vocab import GloVe\r\n",
    "\r\n",
    "glove = GloVe(name='6B')  # global vectors\r\n",
    "\r\n",
    "words = [\"hello\", \"hi\", \"king\", \"president\"]\r\n",
    "vecs = glove.get_vecs_by_tokens(words)\r\n",
    "\r\n",
    "print(vecs.shape)\r\n",
    "print()\r\n",
    "for (i, j) in combinations(range(4), 2):\r\n",
    "    print(words[i], words[j], vecs[i].dot(vecs[j]))\r\n",
    "print()\r\n",
    "print(vecs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 300])\n",
      "\n",
      "hello hi tensor(13.7214)\n",
      "hello king tensor(2.2427)\n",
      "hello president tensor(2.7678)\n",
      "hi king tensor(1.4366)\n",
      "hi president tensor(-2.7832)\n",
      "king president tensor(14.2624)\n",
      "\n",
      "tensor([[-0.3371, -0.2169, -0.0066,  ...,  0.4056,  0.1807,  0.6425],\n",
      "        [ 0.4084, -0.1843, -0.1757,  ..., -0.5265,  0.8163,  0.7427],\n",
      "        [ 0.0034, -0.3461,  0.2814,  ...,  0.0821, -0.6880,  0.3027],\n",
      "        [ 0.4367,  0.1879, -0.1702,  ...,  0.0329, -0.5214,  0.2229]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 10** [5]: Write a new collate function ``collate_into_cbow`` that returns a CBoW representation of each batch, using GloVe.\n",
    "\n",
    "**Task 11** [2]: Write copies of other functions as needed to determine the estimate accuracy of the (optimal) model that incorporates GloVe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "source": [
    "def collate_into_cbow(batch):\r\n",
    "    '''\r\n",
    "    Input:\r\n",
    "    A batch (list) containing single strings of words separated by spaces (sentence strings).\r\n",
    "\r\n",
    "    Returns\r\n",
    "        1. A tensor of labels for each of the sentence in the dataset\r\n",
    "        2. A tensor of the vectors representing each of the sentences in the dataset\r\n",
    "    '''\r\n",
    "    labels = []\r\n",
    "    vecs = []\r\n",
    "    for (label, words) in batch:\r\n",
    "        labels.append(int(label) - 1)\r\n",
    "        # average the word embeddings along columns (axis=0)\r\n",
    "        # make vecs a list of lists instead of a list of tensors, then make the embedded list a tensor.\r\n",
    "        vecs.append(glove.get_vecs_by_tokens(words.split()).mean(dim=0).tolist()) \r\n",
    "    labels = torch.tensor(labels)\r\n",
    "    vecs = torch.tensor(vecs)\r\n",
    "    return labels, vecs\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "source": [
    "dataloader_continuous = DataLoader(train_iter, batch_size=16, shuffle=False,\r\n",
    "                        collate_fn=collate_into_cbow)\r\n",
    "for idx, (lt, tt) in enumerate(dataloader_continuous):\r\n",
    "    print(idx, lt.shape, tt.shape)\r\n",
    "    if idx == 4:\r\n",
    "        break\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "source": [
    "def train_an_epoch_continuous(dataloader_continuous):\r\n",
    "    model.train()  # Sets the module in training mode.\r\n",
    "    log_interval = 500\r\n",
    "\r\n",
    "    for idx, (label, text) in enumerate(dataloader_continuous):\r\n",
    "        model.zero_grad()\r\n",
    "        log_probs = model(text)\r\n",
    "        loss = loss_function(log_probs, label)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        if idx % log_interval == 0 and idx > 0:\r\n",
    "            print(f'At iteration {idx} the loss is {loss:.3f}.')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "source": [
    "def get_Adam_accuracy(dataloader_continuous):\r\n",
    "    model.eval()\r\n",
    "    with torch.no_grad():\r\n",
    "        total_acc, total_count = 0, 0\r\n",
    "        for idx, (label, word_idxs) in enumerate(dataloader_continuous):\r\n",
    "            log_probs = model(word_idxs)\r\n",
    "            total_acc += (log_probs.argmax(1) == label).sum().item()\r\n",
    "            total_count += label.size(0)\r\n",
    "    return total_acc/total_count\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the Adam optimizer\n",
    "\n",
    "The [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) is usually preferred to SGD because of better convergence properites.\n",
    "\n",
    "**Task 12** [3]: Write copies of functions as needed to plot the convergence of the Adam optimizer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "source": [
    "import time\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\r\n",
    "\r\n",
    "validation_accuracies = []\r\n",
    "for epoch in range(1, EPOCHS + 1):\r\n",
    "    epoch_start_time = time.time()\r\n",
    "    train_an_epoch_continuous(train_dataloader)\r\n",
    "    validation_accuracy = get_Adam_accuracy(valid_dataloader)\r\n",
    "    validation_accuracies.append(validation_accuracy)\r\n",
    "    time_taken = time.time() - epoch_start_time\r\n",
    "    print()\r\n",
    "    print(\r\n",
    "        f'After epoch {epoch} the validation accuracy is {validation_accuracy:.3f}.')\r\n",
    "    print()\r\n",
    "\r\n",
    "plt.title(\"Accuracy by Number of Epochs\")\r\n",
    "plt.ylabel(\"Accuracy\")\r\n",
    "plt.xlabel(\"Epochs\")\r\n",
    "plt.grid()\r\n",
    "plt.plot(range(1, EPOCHS+1), validation_accuracies,\r\n",
    "         \"r\", label=\"validation accuracy\")\r\n",
    "plt.legend()\r\n",
    "plt.savefig(f\"AdamAccuracy{EPOCHS}epochs.jpg\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "At iteration 500 the loss is 1.196.\n",
      "At iteration 1000 the loss is 1.005.\n",
      "At iteration 1500 the loss is 1.055.\n",
      "\n",
      "After epoch 1 the validation accuracy is 0.577.\n",
      "\n",
      "At iteration 500 the loss is 0.983.\n",
      "At iteration 1000 the loss is 1.048.\n",
      "At iteration 1500 the loss is 1.008.\n",
      "\n",
      "After epoch 2 the validation accuracy is 0.602.\n",
      "\n",
      "At iteration 500 the loss is 1.032.\n",
      "At iteration 1000 the loss is 0.975.\n",
      "At iteration 1500 the loss is 1.033.\n",
      "\n",
      "After epoch 3 the validation accuracy is 0.609.\n",
      "\n",
      "At iteration 500 the loss is 1.074.\n",
      "At iteration 1000 the loss is 1.052.\n",
      "At iteration 1500 the loss is 1.092.\n",
      "\n",
      "After epoch 4 the validation accuracy is 0.615.\n",
      "\n",
      "At iteration 500 the loss is 1.071.\n",
      "At iteration 1000 the loss is 1.043.\n",
      "At iteration 1500 the loss is 1.020.\n",
      "\n",
      "After epoch 5 the validation accuracy is 0.614.\n",
      "\n",
      "At iteration 500 the loss is 1.042.\n",
      "At iteration 1000 the loss is 1.014.\n",
      "At iteration 1500 the loss is 1.020.\n",
      "\n",
      "After epoch 6 the validation accuracy is 0.615.\n",
      "\n",
      "At iteration 500 the loss is 0.940.\n",
      "At iteration 1000 the loss is 1.073.\n",
      "At iteration 1500 the loss is 1.097.\n",
      "\n",
      "After epoch 7 the validation accuracy is 0.617.\n",
      "\n",
      "At iteration 500 the loss is 1.000.\n",
      "At iteration 1000 the loss is 1.048.\n",
      "At iteration 1500 the loss is 1.033.\n",
      "\n",
      "After epoch 8 the validation accuracy is 0.618.\n",
      "\n",
      "At iteration 500 the loss is 1.126.\n",
      "At iteration 1000 the loss is 1.096.\n",
      "At iteration 1500 the loss is 1.004.\n",
      "\n",
      "After epoch 9 the validation accuracy is 0.620.\n",
      "\n",
      "At iteration 500 the loss is 0.970.\n",
      "At iteration 1000 the loss is 1.120.\n",
      "At iteration 1500 the loss is 0.973.\n",
      "\n",
      "After epoch 10 the validation accuracy is 0.622.\n",
      "\n",
      "At iteration 500 the loss is 1.076.\n",
      "At iteration 1000 the loss is 1.138.\n",
      "At iteration 1500 the loss is 0.992.\n",
      "\n",
      "After epoch 11 the validation accuracy is 0.624.\n",
      "\n",
      "At iteration 500 the loss is 1.019.\n",
      "At iteration 1000 the loss is 1.073.\n",
      "At iteration 1500 the loss is 1.130.\n",
      "\n",
      "After epoch 12 the validation accuracy is 0.625.\n",
      "\n",
      "At iteration 500 the loss is 0.931.\n",
      "At iteration 1000 the loss is 0.962.\n",
      "At iteration 1500 the loss is 1.052.\n",
      "\n",
      "After epoch 13 the validation accuracy is 0.625.\n",
      "\n",
      "At iteration 500 the loss is 0.996.\n",
      "At iteration 1000 the loss is 0.962.\n",
      "At iteration 1500 the loss is 1.015.\n",
      "\n",
      "After epoch 14 the validation accuracy is 0.627.\n",
      "\n",
      "At iteration 500 the loss is 1.022.\n",
      "At iteration 1000 the loss is 0.953.\n",
      "At iteration 1500 the loss is 1.079.\n",
      "\n",
      "After epoch 15 the validation accuracy is 0.628.\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other Optimizations\n",
    "\n",
    "**Task 13** [3]: Briefly desribe 3 ways by which you could make the above code run faster or improve its accuracy.  (You don't have to implement your suggestions.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "source": [
    "'''\r\n",
    "1. We could increase the number of words in our vocabulary by decreasing the min_freq parameter. \r\n",
    "   This would give us more words in our dataset, which could assist with the accuracy of our model.\r\n",
    "2. We could implement k-fold cross validation resampling to optimize the training of our model, \r\n",
    "   which could assist with its accuracy.\r\n",
    "3. We could run an ensemble of classifiers in addition to BoW, such as BERT and word2vec, \r\n",
    "   and use the model with the greatest properly-fitted accuracy.\r\n",
    "'''\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n1. We could increase the number of words in our vocabulary by decreasing the min_freq parameter. \\n   This would give us more words in our dataset, which could assist with the accuracy of our model.\\n2. We could implement k-fold cross validation resampling to optimize the training of our model, \\n   which could assist with its accuracy.\\n3. We could run an ensemble of classifiers in addition to BoW, such as BERT and word2vec, \\n   and use the model with the greatest properly-fitted accuracy.\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 352
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}